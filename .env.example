# BIOwerk Configuration
# Copy this file to .env and update with your values

# ============================================================================
# PostgreSQL Configuration
# ============================================================================
# When using PgBouncer (recommended for production):
# - Set POSTGRES_HOST=pgbouncer and POSTGRES_PORT=6432
# When connecting directly to PostgreSQL (development only):
# - Set POSTGRES_HOST=postgres and POSTGRES_PORT=5432
POSTGRES_HOST=pgbouncer
POSTGRES_PORT=6432
POSTGRES_USER=biowerk
POSTGRES_PASSWORD=biowerk_dev_password
POSTGRES_DB=biowerk

# ============================================================================
# PgBouncer Connection Pooling Configuration
# ============================================================================
# Enable PgBouncer for production-grade connection pooling
# Reduces PostgreSQL memory usage and improves connection reuse

# Pool Mode (transaction | session | statement)
# - transaction: Recommended for microservices (best connection reuse)
#   Connection returned to pool after each transaction
# - session: Traditional mode, connection held until client disconnects
# - statement: Aggressive pooling, connection returned after each statement
PGBOUNCER_POOL_MODE=transaction

# Connection Limits
# Maximum client connections (from application services)
# Formula: (num_services * connections_per_service) + overhead
PGBOUNCER_MAX_CLIENT_CONN=200

# Default pool size (server connections to PostgreSQL)
# This is the main pool of connections kept alive
# Start with expected concurrent queries / databases
PGBOUNCER_DEFAULT_POOL_SIZE=25

# Minimum pool size (always maintained)
# Ensures warm connections are available
PGBOUNCER_MIN_POOL_SIZE=10

# Reserve pool (emergency connections)
# Extra connections when default pool exhausted
PGBOUNCER_RESERVE_POOL_SIZE=10

# Maximum database connections (including reserve)
# Should be less than PostgreSQL max_connections (default: 100)
PGBOUNCER_MAX_DB_CONNECTIONS=50

# Timeouts (seconds)
# Server idle timeout - close idle connections
PGBOUNCER_SERVER_IDLE_TIMEOUT=600

# Logging
# Set to 1 to log connections/disconnections, 0 to disable
PGBOUNCER_LOG_CONNECTIONS=1
PGBOUNCER_LOG_DISCONNECTIONS=1

# ============================================================================
# MongoDB Configuration
# ============================================================================
MONGO_HOST=mongodb
MONGO_PORT=27017
MONGO_USER=biowerk
MONGO_PASSWORD=biowerk_dev_password
MONGO_DB=biowerk

# ============================================================================
# Redis Configuration
# ============================================================================
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# ============================================================================
# Cache Configuration
# ============================================================================
CACHE_TTL=300
CACHE_ENABLED=true

# ============================================================================
# Application Configuration
# ============================================================================
LOG_LEVEL=INFO
ENVIRONMENT=development

# ============================================================================
# Authentication Configuration
# ============================================================================
# IMPORTANT: Change JWT_SECRET_KEY in production! Use: openssl rand -hex 32
JWT_SECRET_KEY=dev-secret-key-change-in-production-use-openssl-rand-hex-32
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7
API_KEY_HEADER=X-API-Key
REQUIRE_AUTH=false

# ============================================================================
# TLS/HTTPS Configuration
# ============================================================================
# Enable TLS/HTTPS for production (requires valid certificates)
# For development, generate self-signed certs: python scripts/generate_certs.py
TLS_ENABLED=false
TLS_CERT_FILE=./certs/cert.pem
TLS_KEY_FILE=./certs/key.pem
TLS_CA_FILE=
TLS_VERIFY_CLIENT=false
# Minimum TLS version: TLSv1.2 or TLSv1.3 (TLSv1.3 recommended for production)
TLS_MIN_VERSION=TLSv1.2
# Custom cipher suite (leave empty for secure defaults)
TLS_CIPHERS=

# ============================================================================
# Rate Limiting Configuration
# ============================================================================
# Enable rate limiting to prevent abuse and DDoS attacks
RATE_LIMIT_ENABLED=true
# Number of requests allowed per time window
RATE_LIMIT_REQUESTS=100
# Time window in seconds
RATE_LIMIT_WINDOW=60
# Strategy: fixed_window, sliding_window (recommended), or token_bucket
RATE_LIMIT_STRATEGY=sliding_window
# Apply rate limiting per IP address
RATE_LIMIT_PER_IP=true
# Apply rate limiting per authenticated user
RATE_LIMIT_PER_USER=true
# Burst size for token bucket strategy (allows temporary bursts)
RATE_LIMIT_BURST=20
# Paths to exclude from rate limiting (comma-separated)
# RATE_LIMIT_EXCLUDE_PATHS=/health,/metrics

# ============================================================================
# Agent URLs (for mesh gateway)
# ============================================================================
AGENT_OSTEON_URL=http://osteon:8001
AGENT_MYOCYTE_URL=http://myocyte:8002
AGENT_SYNAPSE_URL=http://synapse:8003
AGENT_CIRCADIAN_URL=http://circadian:8004
AGENT_NUCLEUS_URL=http://nucleus:8005
AGENT_CHAPERONE_URL=http://chaperone:8006

# ============================================================================
# Audit Logging Configuration
# ============================================================================
# Enable comprehensive audit logging with encryption at rest
AUDIT_ENABLED=true
# Log all API requests (captures method, path, headers, body)
AUDIT_LOG_REQUESTS=true
# Log all API responses (captures status, headers, body)
AUDIT_LOG_RESPONSES=true
# Encrypt sensitive fields (IP addresses, request/response data)
AUDIT_ENCRYPT_SENSITIVE=true
# Default retention period in days (1 year)
AUDIT_RETENTION_DAYS=365
# Retention for authentication events (90 days)
AUDIT_RETENTION_AUTH_DAYS=90
# Retention for data modification events (7 years for compliance)
AUDIT_RETENTION_DATA_DAYS=2555
# Retention for security events (2 years)
AUDIT_RETENTION_SECURITY_DAYS=730
# Collect geolocation data (requires external GeoIP service)
AUDIT_COLLECT_GEO=false
# Maximum size for request/response fields (64KB)
AUDIT_MAX_FIELD_SIZE=65536
# Batch size for bulk audit log writes
AUDIT_BATCH_SIZE=100
# Write audit logs asynchronously for better performance
AUDIT_ASYNC_WRITE=true

# ============================================================================
# Encryption Configuration (for Audit Logs and Sensitive Data)
# ============================================================================
# Enable encryption at rest for sensitive data
ENCRYPTION_ENABLED=true
# IMPORTANT: Master encryption key - MUST be changed in production!
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
# In production, use KMS (AWS KMS, Azure Key Vault, HashiCorp Vault)
ENCRYPTION_MASTER_KEY=change-this-master-key-in-production-min-32-chars-required
# Current encryption key version (increment when rotating keys)
ENCRYPTION_KEY_VERSION=1
# Days before key rotation is recommended (90 days)
ENCRYPTION_KEY_ROTATION_DAYS=90
# Base64-encoded salt for key derivation (auto-generated if not set)
ENCRYPTION_SALT=
# Encryption algorithm (DO NOT CHANGE unless you know what you're doing)
ENCRYPTION_ALGORITHM=AES-256-GCM

# ============================================================================
# LLM Provider Configuration
# ============================================================================
# Primary LLM provider: 'openai', 'anthropic', 'deepseek', 'ollama', or 'local'
# - 'local': Use standalone GGUF models in service directories (NO git commit)
# - 'ollama': Use shared Ollama server (current default)
# - 'openai', 'anthropic', 'deepseek': Cloud APIs (requires keys)
LLM_PROVIDER=ollama

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.7
OPENAI_TIMEOUT=60

# Anthropic Claude Configuration
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_MAX_TOKENS=4096
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_TIMEOUT=60

# DeepSeek Configuration
DEEPSEEK_API_KEY=your-deepseek-api-key-here
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_BASE_URL=https://api.deepseek.com
DEEPSEEK_MAX_TOKENS=4096
DEEPSEEK_TEMPERATURE=0.7
DEEPSEEK_TIMEOUT=60

# Ollama Configuration (Local/Open-Source LLMs)
# Recommended models: phi3:mini, llama3.2, mistral, qwen2.5:7b
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=phi3:mini
OLLAMA_MAX_TOKENS=4096
OLLAMA_TEMPERATURE=0.7
OLLAMA_TIMEOUT=120

# Local Model Configuration (Standalone GGUF files - NOT in git)
# Download models using: ./scripts/download-models.sh
# Each service has its own copy in services/SERVICE_NAME/models/
LOCAL_MODEL_PATH=./models
LOCAL_MODEL_NAME=phi3-mini
LOCAL_MODEL_FILE=model.gguf
LOCAL_MAX_TOKENS=4096
LOCAL_TEMPERATURE=0.7
LOCAL_CONTEXT_SIZE=4096
LOCAL_GPU_LAYERS=0
